{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ensembling_methods.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO6hO36ZbPziXRgyzoo/UNG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kurtispykes/deep-learning-examples/blob/main/ensembling_methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wB6eF1-6CFP7"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import typing as t\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create training data\n",
        "X, y = make_classification(\n",
        "    n_samples=10000,\n",
        "    n_informative=10,\n",
        "    random_state=2022\n",
        ")\n",
        "\n",
        "# split into train and test\n",
        "X_new, X_test = X[:9000, :], X[9000:, ]\n",
        "y_new, y_test = y[:9000], y[9000:]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_new, y_new, \n",
        "    test_size=0.3\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"Train data: {X_train.shape}\\n\\\n",
        "Train labels: {y_train.shape}\\n\\\n",
        "Testing data: {X_test.shape}\\n\\\n",
        "Test labels: {y_test.shape}\\n\\\n",
        "Validation data: {X_val.shape}\\n\\\n",
        "Validation labels: {y_val.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRE2vxhiFfnY",
        "outputId": "c664772e-278f-4b2f-c2e0-6e5af12dd27e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data: (6300, 20)\n",
            "Train labels: (6300,)\n",
            "Testing data: (1000, 20)\n",
            "Test labels: (1000,)\n",
            "Validation data: (2700, 20)\n",
            "Validation labels: (2700,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline"
      ],
      "metadata": {
        "id": "Gtu8fqE9WFZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# building and training model\n",
        "model = tf.keras.Sequential([\n",
        "                            tf.keras.layers.Dense(10, \n",
        "                                                  input_shape=(X_train.shape[1],),\n",
        "                                                  activation=\"relu\"),\n",
        "                            tf.keras.layers.Dense(10,\n",
        "                                                  activation=\"relu\"),\n",
        "                            tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, epochs=20, verbose=0)\n",
        "\n",
        "_, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "_, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_acc}\\n\\\n",
        "Test Accuracy: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y68jOqT5WEVE",
        "outputId": "c73bc4f5-5987-4778-80b5-87a2616764e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9603703618049622\n",
            "Test Accuracy: 0.9610000252723694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross validation Ensemble"
      ],
      "metadata": {
        "id": "9YafHcu7wn70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# building a 3 layer NN \n",
        "def build_model(X:np.array,\n",
        "                y:np.array, \n",
        "                X_val:np.array,\n",
        "                y_val:np.array\n",
        "                ) -> t.Union[t.List[tf.keras.Sequential], t.List[float]]: \n",
        "  model = tf.keras.Sequential([\n",
        "                              tf.keras.layers.Dense(10, \n",
        "                                                    input_shape=(X.shape[1],),\n",
        "                                                    activation=\"relu\"),\n",
        "                              tf.keras.layers.Dense(10,\n",
        "                                                    activation=\"relu\"),\n",
        "                              tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "  ])\n",
        "\n",
        "  model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "  model.fit(X, y, epochs=20, verbose=0)\n",
        "  \n",
        "  _, acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "  return model, acc\n",
        "\n",
        "# to save models and their performance\n",
        "# on the validation data\n",
        "scores = []\n",
        "ensemble = []\n",
        "\n",
        "# create folds\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "for train_idx, val_idx in kfold.split(X_new): \n",
        "  X_train, y_train = X_new[train_idx], y_new[train_idx]\n",
        "  X_val, y_val = X_new[val_idx], y_new[val_idx]\n",
        "  # train a model\n",
        "  model, acc = build_model(X=X_train, y=y_train, X_val=X_val, y_val=y_val) \n",
        "  # saving model and performance\n",
        "  scores.append(acc)\n",
        "  ensemble.append(model)\n",
        "\n",
        "print(f\"Accuracy of Constituents: {scores}\\n\\\n",
        "Expected Accuracy from Ensemble: {np.mean(scores)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1sgqCG6wnZ8",
        "outputId": "f50e0a05-6012-4756-9b09-0bf95feac804"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Constituents: [0.9627777934074402, 0.9538888931274414, 0.9605555534362793, 0.9566666483879089, 0.9688888788223267]\n",
            "Expected Accuracy from Ensemble: 0.9605555534362793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# combining the models to use on test data\n",
        "y_hat = [model.predict(X_test) for model in ensemble]\n",
        "# convert preds to binary \n",
        "y_hat = [list(map(lambda x: 0 if x < 0.5 else 1, preds)) for preds in y_hat]\n",
        "# taking the most common prediction from each model for each instance\n",
        "y_hat_preds = np.array(pd.DataFrame(y_hat).mode().T)\n",
        "# final model on test data\n",
        "accuracy_score(y_test, y_hat_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEpznBomGsrP",
        "outputId": "85e210fc-9cfa-41b1-d11b-c1244a5ef2e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.964"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bagging Ensemble "
      ],
      "metadata": {
        "id": "JPcy5if-FgHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bootstrap(X:np.array, y:np.array, size:int):\n",
        "  # create an index for each instance \n",
        "  idx = [i for i in range(len(X))]\n",
        "  # create a bootstrap dataset of 7500 instances\n",
        "  bootstrap_idx = np.random.choice(range(len(X)), size=size)\n",
        "  # all other instances not in training data \n",
        "  # will be used to validate the model\n",
        "  val_idx = [x for x in idx if x not in bootstrap_idx]\n",
        "  # creating the training and validation datasets \n",
        "  train_data, train_labels = X[bootstrap_idx], y[bootstrap_idx]\n",
        "  val_data, val_labels = X[val_idx], y[val_idx]\n",
        "  return train_data, train_labels, val_data, val_labels\n",
        "\n",
        "def build_model(X:np.array, y:np.array, X_val:np.array, y_val:np.array): \n",
        "  # building and training model\n",
        "  model = tf.keras.Sequential([\n",
        "                              tf.keras.layers.Dense(10, \n",
        "                                                    input_shape=(X.shape[1],),\n",
        "                                                    activation=\"relu\"),\n",
        "                              tf.keras.layers.Dense(10,\n",
        "                                                    activation=\"relu\"),\n",
        "                              tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "  ])\n",
        "\n",
        "  model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "  model.fit(X, y, epochs=20, verbose=0)\n",
        "  _, acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "  return model, val_acc\n",
        "\n",
        "def ensemble_predict(test_data:np.array, ensemble:t.List[tf.keras.Sequential]) -> np.array:\n",
        "  # combining the models to use on test data\n",
        "  y_hat = [model.predict(test_data) for model in ensemble]\n",
        "  # convert preds to binary \n",
        "  y_hat = [list(map(lambda x: 0 if x < 0.5 else 1, preds)) for preds in y_hat]\n",
        "  # taking the most common prediction from each model for each instance\n",
        "  y_hat_preds = np.array(pd.DataFrame(y_hat).mode().T)\n",
        "  return y_hat_preds\n",
        "\n",
        "def train(X:np.array, \n",
        "          y:np.array, \n",
        "          n_models:int, \n",
        "          n_samples:int\n",
        "          ) -> t.Union[\n",
        "                       t.List[tf.keras.Sequential],\n",
        "                       t.List[float],\n",
        "                       float\n",
        "                       ]:\n",
        "\n",
        "  scores = []\n",
        "  ensemble = []\n",
        "  expected_performance = None \n",
        "  \n",
        "  for _ in range(n_models):\n",
        "    train_data, train_labels, val_data, val_labels = create_bootstrap(\n",
        "        X, y, n_samples)\n",
        "    model, acc = build_model(\n",
        "        train_data, train_labels, val_data, val_labels)\n",
        "    ensemble.append(model)\n",
        "    scores.append(acc)\n",
        "  expected_performance = np.mean(scores)\n",
        "  return ensemble, scores, expected_performance\n",
        "\n",
        "ensemble, scores, expected_performance = train(X=X_new, y=y_new, n_models=5, n_samples=8000)\n",
        " \n",
        "\n",
        "print(f\"Accuracy of Constituents: {scores}\\n\\\n",
        "Expected Accuracy from Ensemble: {expected_performance}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtTnQUlhFh13",
        "outputId": "dcf9a5ec-4df8-4f54-ac33-5653f3e1631c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Constituents: [0.9603703618049622, 0.9603703618049622, 0.9603703618049622, 0.9603703618049622, 0.9603703618049622]\n",
            "Expected Accuracy from Ensemble: 0.9603703618049622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ensemble model predictions\n",
        "y_hat_preds = ensemble_predict(X_test, ensemble)\n",
        "accuracy_score(y_test, y_hat_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VvS1q-_1Poi",
        "outputId": "03f174e4-1d44-4679-ee17-9a146bfd68c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.964"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}